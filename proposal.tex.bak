\documentclass{llncs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{subfigure}
\bibliographystyle{splncs}

\begin{document}

\title{Deep Networks for 3D Reconstruction from Endoscopic Video}

\author{Stephen Pizer\inst{1,2}, Julian Rosenman\inst{2,1}}
\institute{Computer Science, University of North Carolina at Chapel Hill, USA \and Radiation Oncology, University of North Carolina at Chapel Hill, USA}
\maketitle

\section{Motivation}
Endoscopy is an in-body examination procedure that enables high-resolution optical visualization of tissue texture and is a critical step in many clinical workflows. However, the use of endoscopy is still highly limited in the context of radiation therapy treatment planning due to the fact that an endoscopic video does not provide explicit 3D spatial information, making it difficult to use for tumor localization. In addition, due to the large amount of redundant information and lack of an efficient method to do video-based comparison, endoscopic video is almost never used for review.

Our group has proposed a pipeline in \cite{zhao16} that can reconstruct a textured 3D surface model, which we call an \textit{endoscopogram}, from multiple 2D endoscopic video frames. The model provides (1) complete 3D anatomical geometry, which facilitates tumor localization; (2) efficient visualization and comparison within and between patients; and (3) the opportunity to register endoscopy data with the other modalities, such as CT, thereby enabling transfer of the tumor information into the other spaces. We have applied this pipeline on nasopharyngoscopic and colonoscopic videos \cite{zhao16,rui16} and showed promising initial results. Preliminary clinical trials also haven shown that tumor location based on the 3D endoscopogram model can achieve within 3mm error on average.

\begin{figure}[!b]
  \centering
  \includegraphics[height=3.5cm]{figures/pipeline}
  \caption{The endoscopogram reconstruction pipeline.}
  %\includegraphics[height=4cm]{syn.png}
  %\caption{Registration error of 24 synthetic deformations.}
\end{figure}

Our pipeline can be generally divided into two steps. First, the \textit{reconstruction} step generates for each 2D frame $\mathcal{F}_i$ a 3D reconstruction $\mathcal{R}_i$ by our novel SfMS (shape-from-Motion-and-Shading) method. Then the \textit{fusion} step fuses all the single-frame reconstructions $\{\mathcal{R}_i\}$ into a single geometry $\mathcal{R}$. Therefore, a robust 3D reconstruction method is required in the first step, and it plays an extremely essential role in producing an accurate final result since it determines the amount of reconstruction error that is propagated into the fusion step.

\section{Existing Work and Limitations}

Recently, there have been attempts in applying state-of-the-art computer vision techniques in various monocular endoscopy applications. In general, monocular 3D reconstruction methods for can be classified into two categories: single-image-based reconstruction and multi-image-based reconstruction. 

A majority of works within the scope of single-image-based reconstruction follow the line of \textit{Shape-from-Shading} (SfS). Given a single image viewing a scene, SfS can estimate the depth of the observed surface by relating the shading information with the surface normal and lighting direction. It turns out that this relationship can be modeled as a partial differential equation (PDE), which then can be solved numerically. 

Multi-image based reconstruction, usually referred as Structured-from-Motion (SfM), produces a sparse scene representation from a sequence of individual frames from the endoscope video. SfM starts off by detecting and matching local features among the set of images, then it incrementally estimates both camera poses and scene structure, represented by a set of 3D points.

Our group has nicely combined the two frameworks into a unified Shape-from-Motion-and-Shading (SfMS) framework. The framework

Recent advance 

\section{Deep Networks for Single Image Reconstruction}

\textbf{Other Related Work Published by Our Group.}
\textbf{Acknowledgement.}









\bibliography{nvidia}
\end{document}
